## 体系架构以及各层协议

![img](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/0fa6c237-a909-4e2a-a771-2c5485cd8ce0.png)

**数据链路层协议：**

* CSMA/CD 协议：表示载波监听多点接入/碰撞检测
    * 可抢占性
    * 半双工介质访问控制协议
* PPP 协议：用户计算机和 ISP 进行通信时所使用的的数据链路协议
* MAC 地址：用于标识网络适配器，全球唯一。地址总共包含 48 位，占 6 字节空间
    * 前 24 位为设备制造商的标识符， 也是组织唯一标识符，后 24 后是序列号

链路层能承载的最大数据量叫做最大传送单元（MTU）



> 例：头部长度为20字节，数据部分长度为2000字节，该数据报需要经过两个网络到达目的主机，这两个网络所允许的最大传输单位MTU分别为1500字节和576字节。
>
> 1、2000字节（加上头部一共2020字节）的数据经过第一个MTU为1500字节的网络时，分为2个分片,分片1（1500字节）携带1480字节的数据，分片2（540字节）携带剩下的520字节的数据。
>
> 2.分片1（1480字节的数据）经过第二个MTU为576字节的网络时，需要继续分片为3个IP小报文（分片3、4、5），分片3和4各自携带556（576-20=556）字节的数据，分片5携带剩下的368字节的数据。
>
> 那么，总共分为了4个IP小报文





**MAC 地址**不需要全球唯一的原因

* 跨局域网的网络传输是通过网络层 IP 协议

- 在不同操作系统上，我们都可以通过软件直接修改网卡的 MAC 地址；
- 只需要保证一个局域网内的 MAC 地址不重复，网络就可以正常工作；

在局域网中一般会使用集线器（Hub）【物理层】 或者交换机（Switch）【数据链路层】

如果使用集线器，那所有数据帧会广播给局域网内的全部主机，所以使用一样的 MAC 地址问题不大

交换机会识别不同 MAC 地址并将数据帧转发给特定主机，这样就会影响网络通信。

![2020-04-29-15881745756775-hub-and-switch](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/2020-04-29-15881745756775-hub-and-switch.png)





网络延迟指从报文开始进入网络到它开始离开网络之间的时间



子网掩码计算：255.255.255.248

248是 11111 000

前面 5 个 1 划分32个子网

3 个 0 划分 8 个主机 去掉 000 和 111 就是6个





**网络层协议**：

路由器处于网络层

* ARP 协议：由 IP 地址获得 MAC 地址
* ICMP 协议：为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议
    * ping：向目的主机发送 ICMP Echo 请求报文，目的主机接收之后发送 Echo 回答报文
        * **使用的协议**
        * DNS(域名->IP)
        * ARP (IP->MAC) 
    * traceroute：用于跟踪一个分组从源点到终点的路径
* IGMP 协议：主要用于建立和管理多播组，对 IP 分组广播进行控制

**ARP 协议**

1. 源主机先向局域网广播发送 ARP 请求
2. 接收到 ARP 请求的主机会检查目的 IP 和自己的 IP 地址是否一致
    1. 如果一致则向源主机发送 ARP 响应
    2. 不一致则忽略请求
3. 源主机接收到 ARP 响应后，会更新本地的缓存表并继续向目的主机发送数据

**传输层：**

* TCP
* UDP

**应用层**：

* 网关

* DNS ：53 端口号，可以使用 UDP 或者 TCP，大部分使用 UDP 传输
* FTP：  控制连接： 21 端口号，数据连接： 20 端口号，使用 TCP 连接
* DHCP：自动配置 IP，子网掩码，网关 IP 地址，使用 UDP

应用层常用端口及传输协议

| 应用             | 应用层协议 | 端口号  | 传输层协议 | 备注                        |
| ---------------- | ---------- | ------- | ---------- | --------------------------- |
| 域名解析         | DNS        | 53      | UDP/TCP    | 长度超过 512 字节时使用 TCP |
| 动态主机配置协议 | DHCP       | 67/68   | UDP        |                             |
| 简单网络管理协议 | SNMP       | 161/162 | UDP        |                             |
| 文件传送协议     | FTP        | 20/21   | TCP        | 控制连接 21，数据连接 20    |
| 远程终端协议     | TELNET     | 23      | TCP        |                             |
| 超文本传送协议   | HTTP       | 80      | TCP        |                             |
| 简单邮件传送协议 | SMTP       | 25      | TCP        |                             |
| 邮件读取协议     | POP3       | 110     | TCP        |                             |
| 网际报文存取协议 | IMAP       | 143     | TCP        |                             |

DNS 域名请求访问流程：本地 DNS 服务器 -> 根 DNS 服务器 然后递归查询 先问 .com IP 中查询再从 .com 服务器中询问



**CGI**

通用网关接口，是外部应用程序（CGI 程序）与 Web 服务器之间的**接口标准**，是在 CGI 程序与 Web 服务器之间传递信息的规程。

CGI方式在遇到连接请求（用户请求）先要创建cgi的子进程，激活一个CGI进程，然后处理请求，处理完后结束这个子进程。这就是fork-and-execute模式。所以 CGI 会性能低下，大量挤占系统资源。

脚本工作流程：

1. 浏览器通过 HTML 表单或超链接请求指向一个 CGI 应用程序的 URL。
2. 服务器收发到请求。
3. 服务器执行所指定的 CGI 应用程序。
4. CGI 应用程序执行所需要的操作，通常是基于浏览者输入的内容。
5. CGI 应用程序把结果格式化为网络服务器和浏览器能够理解的文档（通常是 HTML 网页）。
6. 网络服务器把结果返回到浏览器中。



## TCP/UDP

### UDP 数据报格式

![d4c3a4a1-0846-46ec-9cc3-eaddfca71254](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/d4c3a4a1-0846-46ec-9cc3-eaddfca71254.jpg)

UDP 校验和只提供差错检测，如果出错则丢弃这个 UDP 报文



### TCP 数据报格式

![55dc4e84-573d-4c13-a765-52ed1dd251f9](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/55dc4e84-573d-4c13-a765-52ed1dd251f9.png)



* 序号（Seq）：用于对字节流进行编号，来保证按序交付
* 确认号（ack）：用于接收端确认收到发送端的序号，如果确认号为 `x+1` 那么就说明序号 `x` 为止所有数据已收到

* 数据偏移：tcp 数据偏移表示首部长度， IP 的用于发生分片的情况
* 紧急 URG ：URG=1 时表示紧急指针有效，表示此报文段有紧急数据，不经过缓冲区
* 确认比特（ACK）：ACK=1 时，表示确认号有效
* 推送比特（PSH）：PSH=1，尽快交付给接收端，不用等缓存填满再交付，仍要进入缓冲区
* 复位比特 (RST)：RST=1，表示 TCP 连接出现严重差错，需要重新连接
* 同步比特（SYN）：SYN=1，表示这是连接请求和连接接收报文
* 终止比特（FIN）：FIN=1，表示发送端数据已发送完毕
* 窗口：控制对方发送的数据量

TCP 头部没有选项字段为 20 字节，最多有 60 字节



**TCP 数据报大小**

以太网数据包最初是 1518 字节，后来增加到 1522 字节，其中 1500 为负载（payload），22 字节为头部信息。

IP 数据包在以太网数据包的负载里面，它也有自己的头部信息，最少需要 20  字节，所以 IP 数据包负载最多为 1480 字节

TCP 头部至少需要 20 字节，因此 TCP 数据包的最大负载是 1460 字节。由于 IP 和 TCP 协议往往有额外的头部信息，所以 TCP 负载实际为 1400 字节左右。



### TCP 长连接和短链接

**短链接**： 通信双方有数据需要交互时就建立 TCP 连接，数据发送完成后就断开 TCP 连接。管理起来很简单，不需要额外的控制手段。

**长连接**：在一个TCP连接上可以连续发送多个数据包，在 TCP 连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持（不发生 RST 包和四次挥手）。 

### TCP 的可靠性

1. 解决乱序和冗余问题: **序列号** （Seq ）
2. 解决干扰问题:**校验和** 
3. 解决丢包问题: **确认应答**（ACK), **拥塞控制** , **超时重传**  

### TCP/IP 三次握手和四次挥手

ACK(确认号)、SYN（同步序号）用于请求连接， FIN（终止）用于终止连接

**三次握手**

第一步：A 向 B 发送连接请求报文段， SYN=1，seq=x，需要消耗掉一个序号（seq）

第二步：如果 B 同意，则发送 SYN=1, ACK=1，确认号 ack=x+1(表示 seq 已收到)，再选择一个 seq=y

第三步：A 做同样操作

![e92d0ebc-7d46-413b-aec1-34a39602f787](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/e92d0ebc-7d46-413b-aec1-34a39602f787.png)

**四次挥手**

![f87afe72-c2df-4c12-ac03-9b8d581a8af8](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg)



#### 1.为什么连接时是三次握手, 关闭是四次挥手?

当 Server 端受到 Client 端的 SYN 连接请求时, 可以直接发送 SYN+ACK 报文。关闭连接时，Server 收到 FIN 可能不会立刻关闭通道， 会先回复 ACK，然后把剩下的数据发送完毕时，再发送 FIN 报文，所以需要四次挥手。

#### 2.为什么会有 TIME_WAIT 状态?

1.确保有足够多的时间让对方收到 ACK 包

2.避免新旧连接混淆

#### 3.为什么不能用两次握手连接?

3 次握手是为了初始化 Seq Number 和确保通信双方都做好发送数据的准备。二次握手的话可能会发生死锁，如果 Server 和 Client 端进行通信时， C 发送同步序号，S 接收到了并发送一个确认号，此时按照二次握手协定，此时 S 已经建立连接开始发送数据包，如果 C 端未收到 S 端确认号，则 C 端不会打开链接忽略 S 发送的数据包，而是继续等待 S 端的 ACK 确认号，S 端在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。

#### 4.如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP 有一个保活计时器（KeepAlived），服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

#### 5. 三次握手的缺陷（SYN Flood）

攻击者首先伪造地址对 服务器发起 SYN 请求，服务器回应(SYN+ACK)包，而真实的IP会认为，我没有发送请求，不作回应。服务器没有收到回应，这样的话，服务器不知 道(SYN+ACK)是否发送成功，默认情况下会重试5次（tcp_syn_retries）。这样的话，对于服务器的内存，带宽都有很大的消耗。攻击者 如果处于公网，可以伪造IP的话，对于服务器就很难根据IP来判断攻击者，给防护带来很大的困难。

**防护措施**

* 无效链接监视释放
* 延缓 TCB 分配方法
* 使用 SYN Proxy 防火墙 + SYN Cookie



#### 6. 服务器出现大量 TIME_WAIT 

TIME_WAIT 是服务器请求过于频繁，解决方法：

1. 开启 TCP 连接重用
2. 降低 TIME_WAIT 时间
3. 使用长连接
4. 开启 TCP 快速回收



### TCP 流量控制

流量控制让发送方发送速率不要太快，使接收方来得及接收，也不要使网络发生拥塞。TCP 使用滑动窗口机制来实现流量控制。

![a3253deb-8d21-40a1-aae4-7d178e4aa319](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg)



#### TCP 粘包和拆包

1. 应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。
2. 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。
3. 进行 MSS （最大报文长度）大小的 TCP 分段，当 TCP 报文长度-TCP 头部长度>MSS 的时候将发生拆包。
4. 接收方法不及时读取套接字缓冲区数据，这将发生粘包。

**解决方法**

1. 使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
2. 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。
3. 设置消息边界，服务端从网络流中按消息编辑分离出消息内容，一般使用  ‘\n ’。



### TCP 拥塞控制

拥塞条件：对资源需求总和 > 可用资源

主要通过四个算法进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

TCP 维护以下两个窗口

1. 接收端窗口 rwnd：接收端根据其接受缓存大小所许诺的最新窗口值，反应接收端容量
2. 拥塞窗口 cwnd：发送端根据自己估计得网络拥塞程度而设置的窗口值，反映了网络当前容量

**慢开始和拥塞避免**

**慢开始**

最开始令 cwnd = 1，发送端先发送一个报文段，当收到确认后，将 cwnd 加倍，之后  cwnd = 2、4、8.。。

慢开始每次都是一个轮次加倍，会使 cwnd 增长速度非常快，从而可能发生网络拥塞。

**拥塞避免**

设定一个慢开始门限 ssthresh 当 $cwnd\ge ssthresh$ 时，进入拥塞避免，每个轮次 cwnd + 1

如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始



**快重传和快恢复**

**快重传：**

接收方每收到一个失序的报文就立刻发出重复确认，例如发送方发送了 M1, M2 但是 M3 丢失，此时发送方发送 M4，接收方收到 M4 后立刻发送 M3 的重复确认。

发送方连续接收到 3 个重复确认就应当立即重传对方尚未收到的报文段。



**快恢复**：

1. 当发送方收到连续 3 个重复确认，就执行乘法减小算法，令慢开始门限 ssthresh = cwnd / 2,  cwnd = ssthresh。但接下来不执行慢开始算法。
2. 因为发送方觉得现在没有发生拥塞，而是执行加法增大，每个轮次 cwnd + 1





### TCP 和 UDP 区别

| TCP                | UDP                    |
| ------------------ | ---------------------- |
| 面向连接           | 无连接                 |
| 可靠交付           | 最大可能交付【不可靠】 |
| 面向字节流         | 面向报文               |
| 拥塞控制、流量控制 | 没有拥塞控制           |
| 重量级             | 轻量级                 |



## HTTP

### 1. 在浏览器地址栏输入 URL, 按下回车之后经历的流程

1. DNS 解析 URL

2. TCP 连接三次握手服务端和客户端  
3. 发送 HTTP 请求至服务器  
4. 服务器处理请求并返回 HTTP 报文, 
5. 浏览器解析渲染页面
6. 释放 TCP 连接,



### 2. HTTP 状态码

1xx   ----指示信息--表示请求已接收, 继续处理

2xx  -----成功--表示请求已被成功接收, 理解, 接收

3xx   ----重定向--要完成请求必须进一步操作

4xx   ----客户端错误

5xx   ----服务器错误



### 3. GET 请求和 POST 请求区别

**Http 报文层面**: GET 将请求信息放在 **URL**, POST 放在报文体中, 可以抓包. [安全性并无太大差别]

**数据库层面**:      GET 符合幂等性[一次查询和多次查询一样]和安全性[不改变数据库],  POST 不符合

**其他层面:**          GET 可以被缓存, 被存储, 而 POST 不行

**作用**：			   GET 用于获取资源，POST 用于传输信息

### 4. Cookie 和 Session 的区别

**Cookie**:  由服务器发给客户端的特殊信息, 以文本形式存放在客户端 ( HTTP 响应头中 ). 客户端再次请求时, 会把 Cookie 回发, 服务器收到后, 会解析 Cookie 生成与客户端相对应的内容.

**Session:** 服务端机制. 在服务器上保存的信息, 解析客户端请求并操作 session id, 按需保存状态信息. 

实现方式:  1. Cookie 2. URL 回写实现。

**区别**：

1. Cookie 数据存放在客户的浏览器上， Session 数据存放在服务器上
2. Session 相对于 Cookie 更加安全
3. 若考虑减轻服务器负担， 应当使用 Cookie
4. 存储大小不同， Cookie 小， Session 大
5. 有效期不同
6. Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session

### 5.Token 和 Session 的区别

token 支持跨域访问， 相当于是 Session 空间换时间， token 通过算法验证。 token 有可扩展性，可以防止 CSRF （跨站请求伪造）攻击。



### 6.二维码扫描登录的过程

1. PC 端发送二维码请求给服务器， 服务器生成一个二维码发送给 PC
2. PC 端展现二维码，并开始定期轮询二维码是否被扫成功
3. 手机端扫描二维码，将 token，二维码信息发送给服务器
4. 服务器端二维码 ID 和身份信息绑定并生成一个临时 token 发送给手机端
5. 此时 PC 端更新状态为待确认
6. 手机端携带临时 token 发送给服务器并确认
7. 服务器端收到临时 token 后，发送确认 token 给 PC 端
8. PC 端收到后凭借 token 访问服务器 API



### 7.HTTPS 数据传输流程

非对称密钥：RSA 算法

对称密钥：AES, DES 算法

先使用非对称密钥加密传输（公钥私钥）获取对称密钥的密钥

然后使用对称密钥进行传输（保证效率）

1. 浏览器将支持的加密算法信息发送给服务器
2. 服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器
3. 浏览器验证证书合法性，并结合证书公钥加密信息发送给服务器
4. 服务器使用私钥解密信息， 验证哈希，加密响应信息回发浏览器
5. 浏览器解密响应信息， 并对信息进行验真，之后进行加密数据交互

### 8.HTTPS 和 HTTP 区别

1. HTTPS 需要到 CA 申请证书， HTTP 不需要
2. HTTPS 密文传输， HTTP 明文传输
3. 连接方式不同，HTTPS 默认使用 443 端口， HTTP 使用 80 端口
4. HTTPS = HTTP + 加密 + 认证 + 完整性保护，较 HTTP 安全

### 9.SSL 或者 TLS 是什么

![image-20200714145034756](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/image-20200714145034756.png)



SSL ( Security  Sockets Layer, 安全套接层 )

* 为网络通信提供安全及数据完整性的一种安全协议
* 是操作系统对外的 API, SSL 3.0 后更名为 TLS
* 采用身份验证和数据加密保证网络通信的安全和数据的完整性



### 10. HTTP 1.0/1.1/2.0 的区别

HTTP1.0 和 HTTP1.1 的区别

* **缓存处理**：HTTP1.1 引入了更多可供选择的缓存头来控制缓存策略
* **带宽优化以及网络连接的使用**
* **错误通知处理：**HTTP1.1 引入了更多错误状态响应码
* **Host 头处理**：可以绑定到虚拟主机
* **长连接**：支持长连接



HTTP2.0

* **新的二进制格式**
* **多路复用**
* **header压缩**
* **服务端推送**



## Socket

### I/O 模型

**阻塞式 IO** （BIO）

* 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区才返回
* 进程阻塞，操作系统不被阻塞，其他进程还能运行，这种模型 CPU 利用率会比较高

**非阻塞式 I/O** （NIO）

* 应用进程执行系统调用后，内核返回一个错误码。进程可以继续执行，但是要不断执行系统调用获知 I/O 是否完成，这种方式被称为轮询。
* 这种模型 CPU 利用率较低

**I/O 复用**

* 使用 select 或者 poll 或者 epoll 等待数据，可以等待多个 socket 中任何一个变为可读，这个过程会被阻塞
* 它让单个进程有处理多个 I/O 事件的能力，又被称为事件驱动 I/O

**信号驱动 I/O**

* 相当于非阻塞 I/O 的通知方式，由内核发送 SIGIO 信号，应用进程收到后调用 recvfrom 将数据从内核复制到应用进程中
* CPU 利用率比非阻塞高

**异步 I/O （AIO）**

* 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。
* 和信号驱动 I/O 区别在于异步 I/O 是通知可 I/O 完成， 信号驱动是通知可以 I/O



前 4 中 I/O 也可以称为**同步 I/O**

**同步 I/O** ：将数据从内核缓冲区复制到应用进程缓冲区阶段会发生阻塞。



### epoll、select、poll

**epoll** 是 linux 内核实现 IO 多路复用的一个实现。为同步 I/O。

**IO 多路复用**的意思是在一个操作里同时监听多个输入输出源，在其中一个或多个输入输出源可用的时候返回，然后对其的进行读写操作。

**事件**：是指可读可写事件（可读：内核缓冲区非空，可写：内核缓冲区不满）

**通知**：当事件发生时，主动通知，轮询机制则是通知的反面。



#### epoll

**epoll** 是当一种文件描述符（fd file descriptor）的内核缓冲区非空时，发出可读信号进行通知，当写缓冲区不满时，发送可写信号通知的机制。

**epoll** 核心为 3 个 API，核心数据结构是：1 个红黑树和 1 个双向链表

1. **create**： 内核产生一个 epoll 实例数据结构并返回一个文件描述符，这个特殊的文件描述符是 epoll 实例的句柄。
2. **ctl**：将被监听的文件描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改
3. **wait**：检查 ready list 是否有元素如果有则向用户进程返回 ready list，如果 redy list 比 maxevents 长就只复制前 maxevents 个成员到用户态内存中

![pn7qpmo79b](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/pn7qpmo79b.png)



所有添加到 epoll 中的事件都会与设备(如网卡)驱动程序**建立回调关系**，也就是说相应事件的发生时会调用这里的回调方法。这个回调方法在内核中叫做 **ep_poll_callback**，它会把这样的事件放到上面的 rdllist 双向链表中。



**epoll 的两种触发方式**

1. 水平触发（level trigger LT）: 只**要这个文件描述符还有数据可读，每次 epoll_wait都会返回它的事件**，提醒用户程序去操作；默认。select 和 poll 只支持该模式

2. 边缘触发（Edge trigger ET)：除非新中断到，即使 socket 上的事件还没处理完，也是不会次次从 epoll_wait 返回。

    ![2018110814591325](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/2018110814591325.png)



#### epoll，select，poll 对比

1. **用户态将文件描述符传入内核的方式**

    1. select 创建三个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024。
    2. poll 将传入的 struct pollfd 结构体数组拷贝到内核中进行监听
    3. epoll：内核高速 cache 区建立红黑树和就绪链表，然后通过 **ctl** 函数添加文件描述符在红黑树上增加相应的节点。

2. **内核态检测文件描述符读写状态的方式**

    1. select：采用轮询机制，遍历所有 fd，最后返回一个描述符读写操作是否就绪的 mask 掩码，根据掩码给 fd_set 赋值
    2. poll：  轮询机制，查询 fd 状态，就绪则加入到等待队列中并继续遍历
    3. epoll：回调机制，在 **ctl** 的 add 操作时，不仅将文件描述放到红黑树上，也注册了回调函数，内核检测 fd 时会调用回调函数，该回调函数便将就绪 fd 放入 ready list 上

3. **找到就绪的文件描述符并传递给用户态的方式**

    1. select：将之前传入的 fd_set 拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断，有事件时返回整个集合。
    2. poll：将之前传入的 fd 数组拷贝传出用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。
    3. epoll：wait 函数只需要观察 ready list 上有无数据即可，将链表数据返回给数组并返回就绪的数量，只需要依次遍历即可。其中返回的文件描述符是通过 mmap 让内核和用户共享一块内存进行传递。

    

4. **重复监听的处理方式**

    select 和 poll 都需要将新的监听文件描述符集合/struct pollfd 结构体拷贝传入内核中，重复以上步骤

    epoll 无需重新构建红黑树，沿用已有即可

#### epoll 高效原因

1. select 和 poll 动作基本一致，poll 会采用链表进行 fd 的存储，select 采用 fd 标注位来存放，所以 select 会受到最大连接数限制，poll 不会。select 一般 为 1024
2. select，poll 不会指出哪些文件描述符是就绪的，而是返回整个结合，需要用户自行判断，epoll 返回直接使用即可
3. select，poll 都需要将文件描述符有关数据结构拷贝进内核，再拷贝出来。epoll 的文件描述符本身就在内核态中，系统调用 mmap() 文件映射内存加速内核空间的消息传递，减少复制开销
4. select，poll 采用轮询机制检查就绪状态，epoll 采用回调，当 fd 增加，select，poll 效率会线性降低
5. epoll 的 ET（边缘触发）效率高，系统不会充斥大量你不关心的就绪文件描述符。

> epoll 性能最好是在连接数多且大部分不活跃情况下，少且活跃是 poll 和 select 性能更好
>
> poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
>
> select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。select 可移植性更好，几乎被所有主流平台所支持。

### Socket API 

![20181223095510710](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/20181223095510710.jpg)

![java5-1575455064](%E9%9D%A2%E8%AF%95%E9%A2%98-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/java5-1575455064.jpg)

