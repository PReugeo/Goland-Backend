# 分类算法

## 转换器和预估器

### 转换器(Transformer):特征工程的接口

* 实例化
* 调用
    * fit_transform: == fit + transform
    * fit:求统计量
    * transform: 将统计量应用在数据上, 进行转换



### 估计器(实现了算法的api)

### 模型评估(estimator)

　1. 实例化
 　2. 模型评估 estimator.fit(x_train, y_train)
  　3. 模型准确率 estimator.score()



### 模型选择与调优

* 交叉验证

    * 定义: 将拿到的训练数据分为训练集和验证集, 每次更换不同验证集,可以进行n组实验, 将拿到的n组实验的结果取其平均值作为最终结果, 称为n折交叉验证

* 超参数

* 超参数搜索(网格搜索):

    * 对模型预设几种超参数组合
    * 每组超参数组合使用交叉验证进行评估
    * 选出最优参数组合建立模型

* 实现:  

    * ```sklearn.model_selection.GridSearchCV(estimator, parameter_grid=None, cv=None)```
    * estimator: 估计器对象
    * param_grid: 估计器参数
    * cv: 几折验证
    * fit(): 输入训练数据
    * score(): 准确率

    



## 估计器相关算法

### K-近邻算法

* 原理: 根据邻居推测出类别
* 实现: sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm=“auto”)
* 优点:简单，易于理解，　易于实现，无需训练
* 缺点：　懒惰算法，　对测试样本分类时计算量大，　内存消耗大
    * 必须指定ｋ值，ｋ值选择不当会影响分类精度
* 使用场景：　小数据场景，　k~w数量样本



### 朴素贝叶斯

* 定义:假定特征与特征直接为相互独立的
* 拉普拉斯平滑参数: 防止计算出的分类概率为0
* 实现
    * sklearn.naive_bayes.MultinomialNB(alpha = 1.0)
    * alpha: 拉普拉斯平滑参数
* 优点: 